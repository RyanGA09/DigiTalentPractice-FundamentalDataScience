{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "225cbac5",
   "metadata": {},
   "source": [
    "# Self Practice 1 - Data Scraping\n",
    "\n",
    "___\n",
    "\n",
    "## Material\n",
    "\n",
    "- Pandas\n",
    "- Beautifulsoup\n",
    "- kaggle\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07dcc1b",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b497783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb101ec",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f653799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  nasabah_id  umur jenis_kelamin  pendapatan  saldo_rata_rata  \\\n",
      "0       N001    22     Perempuan     5800000          1508000   \n",
      "1       N002    64     Perempuan     5700000          1254000   \n",
      "2       N003    27     Perempuan     2950000           590000   \n",
      "3       N004    34     Perempuan     3100000           186000   \n",
      "4       N005    45     Laki-Laki     6700000          1474000   \n",
      "\n",
      "   jumlah_transaksi  jenis_produk  frekuensi_kunjungi_cabang  \\\n",
      "0                19      tabungan                          1   \n",
      "1                 9  kartu_kredit                          2   \n",
      "2                12      tabungan                          1   \n",
      "3                16      deposito                          5   \n",
      "4                15  kartu_kredit                          3   \n",
      "\n",
      "  pengguna_mobile_banking  skor_kredit  \n",
      "0                   TIDAK          900  \n",
      "1                   TIDAK          900  \n",
      "2                      YA          500  \n",
      "3                   TIDAK          700  \n",
      "4                      YA          800  \n"
     ]
    }
   ],
   "source": [
    "# Read local CSV file\n",
    "data = pd.read_csv('../data/Data_Nasabah.csv', delimiter=';')\n",
    "\n",
    "# Display the first 5 rows of the dataset\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7be2f9c",
   "metadata": {},
   "source": [
    "## BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90532860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set custom User-Agent header to mimic a normal web browser\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "                  'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                  'Chrome/114.0.0.0 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3390fc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Titles from the Main Page:\n",
      "Empty DataFrame\n",
      "Columns: [Judul Berita]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Part 1: Scrape Kompas.com main page\n",
    "url_main = 'https://www.kompas.com/'\n",
    "\n",
    "response = requests.get(url_main, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    berita_utama = soup.find_all('h3', class_='most__title')\n",
    "\n",
    "    # Extract article titles\n",
    "    judul_berita = [berita.text.strip() for berita in berita_utama]\n",
    "\n",
    "    # Store into a DataFrame\n",
    "    df_berita = pd.DataFrame({'Judul Berita': judul_berita})\n",
    "\n",
    "    print(\"Article Titles from the Main Page:\")\n",
    "    print(df_berita)\n",
    "else:\n",
    "    print(f'Failed to access URL. Status code: {response.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15f167a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Article Details:\n",
      "Title: China Akan Larang Semua Film dari AS, Balas Tarif Impor 104 Persen Trump\n",
      "Published Date: 09/04/2025, 12:31 WIB\n",
      "Tags: tarif impor Amerika, tarif impor Trump, tarif impor as, Kementerian Luar Negeri China, Beijing, Amerika Serikat, Tarif impor Trump\n"
     ]
    }
   ],
   "source": [
    "# Part 2: Scrape a specific Kompas.com article page\n",
    "url_article = 'https://www.kompas.com/global/read/2025/04/09/123149070/china-akan-larang-semua-film-dari-as-balas-tarif-impor-104-persen-trump'\n",
    "\n",
    "response = requests.get(url_article, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract article title\n",
    "    content_title = soup.find('h1').text.strip()\n",
    "\n",
    "    # Extract publication date\n",
    "    content_published_date = soup.find('meta', property='article:published_time')\n",
    "    if content_published_date:\n",
    "        utc_time = datetime.fromisoformat(content_published_date['content'].replace('Z', '+00:00'))\n",
    "        wib_time = utc_time.astimezone(pytz.timezone('Asia/Jakarta'))\n",
    "        published_date = wib_time.strftime('%d/%m/%Y, %H:%M WIB')\n",
    "    else:\n",
    "        published_date = \"Publication date not found\"\n",
    "\n",
    "    # Extract article tags\n",
    "    content_tags = soup.find('meta', {'name': 'keywords'})\n",
    "    tags = content_tags['content'] if content_tags else \"Tags not found\"\n",
    "\n",
    "    print(\"\\nArticle Details:\")\n",
    "    print(\"Title:\", content_title)\n",
    "    print(\"Published Date:\", published_date)\n",
    "    print(\"Tags:\", tags)\n",
    "\n",
    "else:\n",
    "    print(f'Failed to access URL. Status code: {response.status_code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f8bf3f",
   "metadata": {},
   "source": [
    "## Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "690bfe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle: Download dataset using API\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a48987ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/juhibhojani/house-price\n",
      "Dataset successfully downloaded and extracted to folder: ../data\n"
     ]
    }
   ],
   "source": [
    "dataset = 'juhibhojani/house-price'\n",
    "download_path = '../data'\n",
    "\n",
    "# Download and unzip dataset\n",
    "api.dataset_download_files(dataset, path=download_path, unzip=True)\n",
    "print(f\"Dataset successfully downloaded and extracted to folder: {download_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2774f1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the folder:\n",
      "Data_Nasabah.csv\n",
      "house_prices.csv\n"
     ]
    }
   ],
   "source": [
    "# List files in the download directory\n",
    "files = os.listdir(download_path)\n",
    "print(\"Contents of the folder:\")\n",
    "for f in files:\n",
    "    print(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
